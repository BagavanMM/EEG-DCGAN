{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =5\n",
    "learning_rate = 0.0001\n",
    "dropout_level = 0.05\n",
    "nz = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights initliazer\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv1d):\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            torch.nninit.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEG_Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EEG_CNN_Gen, self).__init__()\n",
    "\n",
    "        self.nz = nz\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Linear(self.nz, 640),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.ConvTranspose1d(in_channels = 16, out_channels = 16, kernel_size = 22, stride = 4),\n",
    "            nn.PReLU()\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.ConvTranspose1d(in_channels = 16, out_channels = 16, kernel_size = 18, stride = 2), \n",
    "            nn.PRelu()\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.ConvTranspose1d(in_channels = 16, out_channels = 2, kernel_size = 16, stride = 4),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, z):\n",
    "        out = self.layer(z)\n",
    "        out = out.view(out.size(0), 16, 40)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEG_Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EEG_Discriminator, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=2, out_channels = 16, kernel_size = 10, stridde = 2),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.LeakyReLU(0.2), \n",
    "            nn.MaxPool1d(2)\n",
    "        )\n",
    "\n",
    "        self.dense_layers = nn.Sequential(\n",
    "            nn.Linear(5968, 600), \n",
    "            nn.LeakyReLU(0.2), \n",
    "            nn.Linear(600, 1)\n",
    "        )\n",
    "\n",
    "        def forward(self, x):\n",
    "            out = self.layer1(x)\n",
    "            out = out.view(out.size(0), -1)\n",
    "            out = self.dense_layers(out)\n",
    "            return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcgan(datarain, label, nseed):\n",
    "    random.seed(nseed)\n",
    "    np.random.seed(nseed)\n",
    "    torch.manual_seed(nseed)\n",
    "    \n",
    "    datatrain = torch.from_numpy(datatrain)\n",
    "    label = torch.from_numpy(label)\n",
    "\n",
    "    dataset = torch.utils.data.TensorDataset(datatrain, label)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    gen = EEG_Generator().to(device)\n",
    "    dis = EEG_Discriminator().to(device)\n",
    "    gen.apply(weights_init)\n",
    "    dis.apply(weights_init)\n",
    "\n",
    "    # loss function\n",
    "    adversarial_loss = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # Opt\n",
    "    optimizer_G = torch.optim.Adam(gen.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "    optimizer_D = torch.optim.Adam(dis.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "\n",
    "    Tensor = torch.cuda.Floattensor if torch.cuda.is_available else torch.FloatTensor\n",
    "\n",
    "    real_label = 1\n",
    "    fake_label = 0 \n",
    "    new_data =[]\n",
    "    global_step = 0\n",
    "\n",
    "    # TRAINING GAN\n",
    "    dis.train()\n",
    "    gen.train()\n",
    "\n",
    "    for epoch in range(1200):\n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            imgs, _ = data\n",
    "            imgs = imgs.to(device)\n",
    "\n",
    "            # configure inputs\n",
    "            real_data = imgs.type(Tensor)\n",
    "            label = torch.ones(imgs.shape[0], 1).to(device)\n",
    "            z = torch.randn(imgs.shape[0], nz).to(device)\n",
    "\n",
    "            if i % 5 == 0:\n",
    "                # train discriminator\n",
    "\n",
    "                print(\"Discriminator\")\n",
    "\n",
    "                ooptimizer_D.zero_grad()\n",
    "                output_real = dis(real_data)\n",
    "                \n",
    "                # calclaute error and backprop\n",
    "                errD_real = adversarial_loss(output_real, label)\n",
    "                errD_real.backward()\n",
    "\n",
    "                # train with fake\n",
    "                fake_data = generator(z)\n",
    "                label = torch.zeros(imgs.shape[0], 1).to(device)\n",
    "                output_fake = dis(fake_data)\n",
    "                errD_fake = adversarial_loss(output_fake, label)\n",
    "                errD_fake.backward()\n",
    "                errD = errD_real + errD_fake\n",
    "                optimizer_D.step()\n",
    "\n",
    "            if i % 1 == 0:\n",
    "                # train generator\n",
    "                print(\"Generator\")\n",
    "\n",
    "                z = torch.randn(imgs.shape[0], nz).to(device)\n",
    "                fake_data = gen(z)\n",
    "\n",
    "                # reset grads\n",
    "                optimizer_G.zero_grad()\n",
    "\n",
    "                output = dis(fake_data)\n",
    "                bceloss = adversarial_loss(output, torch.ones(imgs.shape[0], 1).to(device))\n",
    "                errG = bceloss\n",
    "                errG.backward()\n",
    "                optimizer_G.step()\n",
    "            \n",
    "            print(\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\" % (epoch, 1200, i, len(dataloader), errD.item(), errG.item()))\n",
    "\n",
    "    # geenrate data\n",
    "    dis.eval()\n",
    "    gen.eval()\n",
    "    for epcoh in range(100):\n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            imgs, _ = data\n",
    "            imgs = imgs.to(device)\n",
    "            z = torch.randn(imgs.shape[0], nz).to(device)\n",
    "\n",
    "            fake_data = gen(z)\n",
    "            output = dis(fake_data)\n",
    "\n",
    "            if i % 200 == 0:\n",
    "                fake_data = fake_data.data[:25].cpu().numpy()\n",
    "                new_data.append(fake_data)\n",
    "    \n",
    "    new_data = np.concatenate(new_data)\n",
    "    new_data = np.asarray(new_data)\n",
    "    print(new_data.shape)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ab7cd6c081d5eeceaa240905fae0db651638a012a37ba75194f5d8a8dc362d7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('BCI-stuff')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
